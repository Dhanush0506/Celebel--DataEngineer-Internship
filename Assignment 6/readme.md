
---

## 📝 Quick Overview

This assignment demonstrates:

- ✅ Secure data movement from local servers using **Self-hosted Integration Runtime (SHIR)**  
- 📂 Integration of **FTP/SFTP data sources** into Azure Data Factory  
- 🔁 Building **incremental data pipelines** with **daily automation**  
- 📆 Configuring **monthly triggers** for the last Saturday of the month  
- 🔄 Implementing **retry logic** for transient failure recovery  

These components together form the foundation of reliable and scalable cloud-based data workflows in modern data engineering.

---

## 📄 Solution Files

| File Name         | Description |
|------------------|-------------|
| [`Solution1.md`](Solution1.md) | Configure Self-hosted Integration Runtime and load data from a local server into Azure SQL Database. |
| [`Solution2.md`](Solution2.md) | Set up FTP/SFTP connection and create a pipeline to extract data in ADF. |
| [`Solution3.md`](Solution3.md) | Design an incremental data load pipeline with watermarking/change tracking and daily automation. |
| [`Solution4.md`](Solution4.md) | Automate a pipeline to trigger on the last Saturday of every month using custom time-based triggers. |
| [`Solution5.md`](Solution5.md) | Implement retry logic to handle transient failures during data extraction and processing. |

---

Feel free to explore each file for detailed implementation steps and explanations.


